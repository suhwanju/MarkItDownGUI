#!/usr/bin/env python3
"""
OCR UI Integration - Code Analysis & Quality Assessment
Static analysis and logical testing without runtime dependencies

Comprehensive QA analysis of OCR UI Status Integration feature
"""

import sys
import ast
import re
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Any

# Project paths
project_root = Path(__file__).parent
ocr_ui_path = project_root / "markitdown_gui" / "core" / "ocr_enhancements" / "ui_integrations"
ui_components_path = project_root / "markitdown_gui" / "ui" / "components"
config_path = project_root / "config" / "settings.ini"


class OCRUIIntegrationQAAnalyzer:
    """OCR UI Integration ì •ì  ë¶„ì„ ë° í’ˆì§ˆ í‰ê°€"""

    def __init__(self):
        self.analysis_results = {}
        self.findings = []
        self.recommendations = []
        self.quality_score = 0
        self.start_time = datetime.now()

    def analyze_code_structure(self) -> Dict[str, Any]:
        """ì½”ë“œ êµ¬ì¡° ë¶„ì„"""
        print("1. ì½”ë“œ êµ¬ì¡° ë¶„ì„ ì¤‘...")

        analysis = {
            'test_name': 'Code Structure Analysis',
            'passed': True,
            'issues': [],
            'metrics': {},
            'files_analyzed': []
        }

        # OCR UI Integration íŒŒì¼ë“¤ ë¶„ì„
        ocr_files = [
            ocr_ui_path / "ocr_status_provider.py",
            ocr_ui_path / "ocr_progress_tracker.py",
            ocr_ui_path / "ocr_result_formatter.py"
        ]

        ui_files = [
            ui_components_path / "file_list_widget.py",
            ui_components_path / "progress_widget.py"
        ]

        all_files = ocr_files + ui_files

        for file_path in all_files:
            if file_path.exists():
                file_analysis = self._analyze_python_file(file_path)
                analysis['files_analyzed'].append(file_analysis)

                # íŒŒì¼ë³„ ì´ìŠˆ ì²´í¬
                if file_analysis['lines_of_code'] > 1000:
                    analysis['issues'].append(f"{file_path.name}: íŒŒì¼ì´ ë„ˆë¬´ í¼ ({file_analysis['lines_of_code']} ì¤„)")

                if file_analysis['complexity_score'] > 20:
                    analysis['issues'].append(f"{file_path.name}: ë³µì¡ë„ê°€ ë†’ìŒ ({file_analysis['complexity_score']})")

                if file_analysis['docstring_coverage'] < 0.8:
                    analysis['issues'].append(f"{file_path.name}: ë¬¸ì„œí™” ë¶€ì¡± ({file_analysis['docstring_coverage']:.1%})")
            else:
                analysis['issues'].append(f"íŒŒì¼ ì—†ìŒ: {file_path}")
                analysis['passed'] = False

        # ì „ì²´ ë©”íŠ¸ë¦­ ê³„ì‚°
        if analysis['files_analyzed']:
            total_lines = sum(f['lines_of_code'] for f in analysis['files_analyzed'])
            avg_complexity = sum(f['complexity_score'] for f in analysis['files_analyzed']) / len(analysis['files_analyzed'])
            avg_docstring_coverage = sum(f['docstring_coverage'] for f in analysis['files_analyzed']) / len(analysis['files_analyzed'])

            analysis['metrics'] = {
                'total_lines_of_code': total_lines,
                'average_complexity': avg_complexity,
                'average_docstring_coverage': avg_docstring_coverage,
                'files_count': len(analysis['files_analyzed'])
            }

        return analysis

    def _analyze_python_file(self, file_path: Path) -> Dict[str, Any]:
        """Python íŒŒì¼ ë¶„ì„"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            tree = ast.parse(content)

            # ê¸°ë³¸ ë©”íŠ¸ë¦­
            lines_of_code = len([line for line in content.split('\n') if line.strip() and not line.strip().startswith('#')])

            # í´ë˜ìŠ¤ì™€ í•¨ìˆ˜ ë¶„ì„
            classes = [node for node in ast.walk(tree) if isinstance(node, ast.ClassDef)]
            functions = [node for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]

            # ë³µì¡ë„ ê³„ì‚° (ê°„ë‹¨í•œ ë²„ì „)
            complexity_score = self._calculate_complexity(tree)

            # ë¬¸ì„œí™” í™•ì¸
            docstring_coverage = self._calculate_docstring_coverage(classes + functions)

            # ì„í¬íŠ¸ ë¶„ì„
            imports = [node for node in ast.walk(tree) if isinstance(node, (ast.Import, ast.ImportFrom))]

            return {
                'file_name': file_path.name,
                'lines_of_code': lines_of_code,
                'classes_count': len(classes),
                'functions_count': len(functions),
                'imports_count': len(imports),
                'complexity_score': complexity_score,
                'docstring_coverage': docstring_coverage,
                'classes': [cls.name for cls in classes],
                'functions': [func.name for func in functions if not func.name.startswith('_')]
            }

        except Exception as e:
            return {
                'file_name': file_path.name,
                'error': str(e),
                'lines_of_code': 0,
                'complexity_score': 0,
                'docstring_coverage': 0
            }

    def _calculate_complexity(self, tree: ast.AST) -> int:
        """ë³µì¡ë„ ê³„ì‚° (ìˆœí™˜ ë³µì¡ë„ ê¸°ë°˜)"""
        complexity = 1  # ê¸°ë³¸ê°’

        for node in ast.walk(tree):
            if isinstance(node, (ast.If, ast.While, ast.For, ast.Try, ast.With)):
                complexity += 1
            elif isinstance(node, ast.BoolOp):
                complexity += len(node.values) - 1

        return complexity

    def _calculate_docstring_coverage(self, nodes: List[ast.AST]) -> float:
        """ë¬¸ì„œí™” ì»¤ë²„ë¦¬ì§€ ê³„ì‚°"""
        if not nodes:
            return 1.0

        documented = 0
        for node in nodes:
            if ast.get_docstring(node):
                documented += 1

        return documented / len(nodes)

    def analyze_feature_integration(self) -> Dict[str, Any]:
        """ê¸°ëŠ¥ í†µí•© ë¶„ì„"""
        print("2. ê¸°ëŠ¥ í†µí•© ë¶„ì„ ì¤‘...")

        analysis = {
            'test_name': 'Feature Integration Analysis',
            'passed': True,
            'issues': [],
            'integration_points': [],
            'recommendations': []
        }

        # FileListWidget í†µí•© í™•ì¸
        file_list_path = ui_components_path / "file_list_widget.py"
        if file_list_path.exists():
            with open(file_list_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # OCR ê´€ë ¨ ì„í¬íŠ¸ í™•ì¸
            if 'ocr_enhancements.ui_integrations' in content:
                analysis['integration_points'].append("FileListWidget: OCR ìƒíƒœ ì œê³µì í†µí•© í™•ì¸")
            else:
                analysis['issues'].append("FileListWidget: OCR í†µí•© ì„í¬íŠ¸ê°€ ì—†ìŒ")
                analysis['passed'] = False

            # ì˜µì…”ë„ ì„í¬íŠ¸ íŒ¨í„´ í™•ì¸
            if 'try:' in content and 'OCRStatusProvider' in content:
                analysis['integration_points'].append("FileListWidget: ì˜µì…”ë„ OCR ì„í¬íŠ¸ íŒ¨í„´ ì‚¬ìš©")
            else:
                analysis['issues'].append("FileListWidget: ì•ˆì „í•œ ì„í¬íŠ¸ íŒ¨í„´ ë¶€ì¡±")

            # OCR ì»¬ëŸ¼ ì¶”ê°€ ë¡œì§ í™•ì¸
            if 'OCR' in content and 'columns.append' in content:
                analysis['integration_points'].append("FileListWidget: OCR ì»¬ëŸ¼ ë™ì  ì¶”ê°€ êµ¬í˜„")
            else:
                analysis['issues'].append("FileListWidget: OCR ì»¬ëŸ¼ ì¶”ê°€ ë¡œì§ ë¯¸í™•ì¸")

        # ProgressWidget í†µí•© í™•ì¸
        progress_path = ui_components_path / "progress_widget.py"
        if progress_path.exists():
            with open(progress_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # OCR ì§„í–‰ë¥  ì¶”ì  í™•ì¸
            if 'OCRProgressTracker' in content or 'ocr_stage' in content:
                analysis['integration_points'].append("ProgressWidget: OCR ì§„í–‰ë¥  ì¶”ì  í†µí•©")
            else:
                analysis['recommendations'].append("ProgressWidget: OCR ì§„í–‰ë¥  í†µí•© ê¶Œì¥")

        # ì„¤ì • íŒŒì¼ í™•ì¸
        if config_path.exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                config_content = f.read()

            if '[ocr_enhancements]' in config_content:
                analysis['integration_points'].append("Configuration: OCR ì„¤ì • ì„¹ì…˜ ì¡´ì¬")

                # í•„ìˆ˜ ì„¤ì • í™•ì¸
                required_settings = ['enabled', 'preprocessing_enabled', 'post_processing_enabled']
                for setting in required_settings:
                    if setting in config_content:
                        analysis['integration_points'].append(f"Configuration: {setting} ì„¤ì • í™•ì¸")
                    else:
                        analysis['issues'].append(f"Configuration: {setting} ì„¤ì • ëˆ„ë½")
            else:
                analysis['issues'].append("Configuration: OCR ì„¤ì • ì„¹ì…˜ ì—†ìŒ")
                analysis['passed'] = False

        return analysis

    def analyze_ui_patterns(self) -> Dict[str, Any]:
        """UI íŒ¨í„´ ë¶„ì„"""
        print("3. UI íŒ¨í„´ ë¶„ì„ ì¤‘...")

        analysis = {
            'test_name': 'UI Patterns Analysis',
            'passed': True,
            'issues': [],
            'patterns_found': [],
            'design_quality': {}
        }

        # OCR Status Provider ë¶„ì„
        status_provider_path = ocr_ui_path / "ocr_status_provider.py"
        if status_provider_path.exists():
            with open(status_provider_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # ìœ„ì ¯ íŒ¨í„´ í™•ì¸
            if 'class OCRStatusBadge(QLabel)' in content:
                analysis['patterns_found'].append("Status Badge: QLabel ê¸°ë°˜ ì»¤ìŠ¤í…€ ìœ„ì ¯")

            if 'class OCRMethodBadge(QLabel)' in content:
                analysis['patterns_found'].append("Method Badge: QLabel ê¸°ë°˜ ì»¤ìŠ¤í…€ ìœ„ì ¯")

            # ìºì‹± íŒ¨í„´ í™•ì¸
            if 'QCache' in content:
                analysis['patterns_found'].append("Caching: QCache í™œìš©í•œ ì„±ëŠ¥ ìµœì í™”")
            else:
                analysis['issues'].append("Status Provider: ìºì‹± ë¯¸êµ¬í˜„ìœ¼ë¡œ ì„±ëŠ¥ ì´ìŠˆ ê°€ëŠ¥")

            # ì‹œê·¸ë„-ìŠ¬ë¡¯ íŒ¨í„´ í™•ì¸
            if 'pyqtSignal' in content:
                analysis['patterns_found'].append("Signals: PyQt ì‹œê·¸ë„-ìŠ¬ë¡¯ íŒ¨í„´ ì‚¬ìš©")

            # ë°°ì§€ í¬ê¸° ì¼ê´€ì„± í™•ì¸
            if 'setFixedSize(20, 16)' in content:
                analysis['patterns_found'].append("UI Consistency: ê³ ì • í¬ê¸° ë°°ì§€ ì‚¬ìš©")

        # OCR Progress Tracker ë¶„ì„
        progress_tracker_path = ocr_ui_path / "ocr_progress_tracker.py"
        if progress_tracker_path.exists():
            with open(progress_tracker_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # ë‹¨ê³„ë³„ ì§„í–‰ë¥  í™•ì¸
            if 'OCRStageProgressBar' in content:
                analysis['patterns_found'].append("Progress Tracking: ë‹¨ê³„ë³„ ì§„í–‰ë¥  ë°”")

            # ì‹œê°„ ì¶”ì • ê¸°ëŠ¥ í™•ì¸
            if 'estimated_completion' in content:
                analysis['patterns_found'].append("Time Estimation: ì™„ë£Œ ì‹œê°„ ì¶”ì • ê¸°ëŠ¥")

            # íƒ€ì´ë¨¸ ê¸°ë°˜ ì—…ë°ì´íŠ¸ í™•ì¸
            if 'QTimer' in content:
                analysis['patterns_found'].append("Real-time Updates: íƒ€ì´ë¨¸ ê¸°ë°˜ ì£¼ê¸°ì  ì—…ë°ì´íŠ¸")

        # OCR Result Formatter ë¶„ì„
        result_formatter_path = ocr_ui_path / "ocr_result_formatter.py"
        if result_formatter_path.exists():
            with open(result_formatter_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # íƒ­ ìœ„ì ¯ íŒ¨í„´ í™•ì¸
            if 'QTabWidget' in content:
                analysis['patterns_found'].append("Result Display: íƒ­ ê¸°ë°˜ ê²°ê³¼ í‘œì‹œ")

            # ì‹ ë¢°ë„ ì‹œê°í™” í™•ì¸
            if 'ConfidenceScoreWidget' in content:
                analysis['patterns_found'].append("Confidence Display: ì‹ ë¢°ë„ ì‹œê°í™” ìœ„ì ¯")

            # í’ˆì§ˆ ë©”íŠ¸ë¦­ í‘œì‹œ í™•ì¸
            if 'QualityMetricsWidget' in content:
                analysis['patterns_found'].append("Quality Metrics: í’ˆì§ˆ ë©”íŠ¸ë¦­ í‘œì‹œ ìœ„ì ¯")

        # ë””ìì¸ í’ˆì§ˆ í‰ê°€
        analysis['design_quality'] = {
            'widget_consistency': len([p for p in analysis['patterns_found'] if 'fixed_size' in p.lower() or 'consistency' in p.lower()]) > 0,
            'performance_optimization': len([p for p in analysis['patterns_found'] if 'caching' in p.lower() or 'timer' in p.lower()]) > 0,
            'user_feedback': len([p for p in analysis['patterns_found'] if 'progress' in p.lower() or 'confidence' in p.lower()]) > 0,
            'modular_design': len([p for p in analysis['patterns_found'] if 'widget' in p.lower()]) >= 3
        }

        return analysis

    def analyze_performance_considerations(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ê³ ë ¤ì‚¬í•­ ë¶„ì„"""
        print("4. ì„±ëŠ¥ ê³ ë ¤ì‚¬í•­ ë¶„ì„ ì¤‘...")

        analysis = {
            'test_name': 'Performance Considerations',
            'passed': True,
            'issues': [],
            'optimizations_found': [],
            'potential_bottlenecks': []
        }

        # ìºì‹± ì „ëµ ë¶„ì„
        status_provider_path = ocr_ui_path / "ocr_status_provider.py"
        if status_provider_path.exists():
            with open(status_provider_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # ìºì‹œ êµ¬í˜„ í™•ì¸
            cache_patterns = [
                ('_status_cache: QCache', 'ìƒíƒœ ìºì‹œ'),
                ('_method_cache: QCache', 'ë°©ë²• ìºì‹œ'),
                ('_badge_cache: QCache', 'ë°°ì§€ ìºì‹œ')
            ]

            for pattern, description in cache_patterns:
                if pattern.split(':')[0] in content:
                    analysis['optimizations_found'].append(f"Caching: {description} êµ¬í˜„")
                else:
                    analysis['potential_bottlenecks'].append(f"Missing: {description} ë¯¸êµ¬í˜„")

            # ìºì‹œ í¬ê¸° ì œí•œ í™•ì¸
            if 'QCache(1000)' in content or 'QCache(500)' in content:
                analysis['optimizations_found'].append("Cache Management: ì ì ˆí•œ ìºì‹œ í¬ê¸° ì œí•œ")
            else:
                analysis['issues'].append("Cache: ìºì‹œ í¬ê¸° ì œí•œ ë¯¸ì„¤ì •ìœ¼ë¡œ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°€ëŠ¥")

        # ë°°ì¹˜ ì²˜ë¦¬ í™•ì¸
        progress_tracker_path = ocr_ui_path / "ocr_progress_tracker.py"
        if progress_tracker_path.exists():
            with open(progress_tracker_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # íƒ€ì´ë¨¸ ê¸°ë°˜ ì¼ê´„ ì—…ë°ì´íŠ¸ í™•ì¸
            if '_update_timer' in content and '500' in content:
                analysis['optimizations_found'].append("Batch Updates: 0.5ì´ˆ ê°„ê²© ì¼ê´„ ì—…ë°ì´íŠ¸")
            else:
                analysis['potential_bottlenecks'].append("Real-time Updates: ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ë¡œ ì„±ëŠ¥ ì €í•˜ ê°€ëŠ¥")

            # ë©”ëª¨ë¦¬ ì •ë¦¬ í™•ì¸
            if 'clear_tracking_data' in content:
                analysis['optimizations_found'].append("Memory Management: ì¶”ì  ë°ì´í„° ì •ë¦¬ ê¸°ëŠ¥")
            else:
                analysis['issues'].append("Memory: ë©”ëª¨ë¦¬ ì •ë¦¬ ê¸°ëŠ¥ ë¯¸êµ¬í˜„")

        # UI ë°˜ì‘ì„± ìµœì í™” í™•ì¸
        result_formatter_path = ocr_ui_path / "ocr_result_formatter.py"
        if result_formatter_path.exists():
            with open(result_formatter_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # ì§€ì—° ë¡œë”© íŒ¨í„´ í™•ì¸
            if 'create_compact_display' in content:
                analysis['optimizations_found'].append("Lazy Loading: ê°„ì†Œ í‘œì‹œ ìœ„ì ¯ìœ¼ë¡œ ì§€ì—° ë¡œë”©")
            else:
                analysis['potential_bottlenecks'].append("UI Responsiveness: ëŒ€ëŸ‰ ë°ì´í„° í‘œì‹œì‹œ ë°˜ì‘ì„± ì €í•˜ ê°€ëŠ¥")

        # íŒŒì¼ í¬ê¸° ê¸°ë°˜ ì ì¬ì  ì´ìŠˆ ì˜ˆì¸¡
        large_files = []
        for file_path in [status_provider_path, progress_tracker_path, result_formatter_path]:
            if file_path.exists():
                size = file_path.stat().st_size
                if size > 50000:  # 50KB ì´ìƒ
                    large_files.append(f"{file_path.name}: {size//1024}KB")

        if large_files:
            analysis['potential_bottlenecks'].extend([f"Large File: {f}" for f in large_files])

        return analysis

    def analyze_error_handling(self) -> Dict[str, Any]:
        """ì—ëŸ¬ ì²˜ë¦¬ ë¶„ì„"""
        print("5. ì—ëŸ¬ ì²˜ë¦¬ ë¶„ì„ ì¤‘...")

        analysis = {
            'test_name': 'Error Handling Analysis',
            'passed': True,
            'issues': [],
            'error_handling_patterns': [],
            'robustness_score': 0
        }

        patterns_found = 0
        total_patterns_checked = 0

        # ê° íŒŒì¼ì˜ ì—ëŸ¬ ì²˜ë¦¬ íŒ¨í„´ í™•ì¸
        files_to_check = [
            ocr_ui_path / "ocr_status_provider.py",
            ocr_ui_path / "ocr_progress_tracker.py",
            ocr_ui_path / "ocr_result_formatter.py"
        ]

        for file_path in files_to_check:
            if file_path.exists():
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                # Try-except ë¸”ë¡ í™•ì¸
                total_patterns_checked += 1
                if 'try:' in content and 'except' in content:
                    patterns_found += 1
                    analysis['error_handling_patterns'].append(f"{file_path.name}: try-except ë¸”ë¡ ì‚¬ìš©")
                else:
                    analysis['issues'].append(f"{file_path.name}: ì˜ˆì™¸ ì²˜ë¦¬ ë¶€ì¡±")

                # ë¡œê¹… í™•ì¸
                total_patterns_checked += 1
                if 'logger.' in content:
                    patterns_found += 1
                    analysis['error_handling_patterns'].append(f"{file_path.name}: ë¡œê¹… êµ¬í˜„")
                else:
                    analysis['issues'].append(f"{file_path.name}: ë¡œê¹… ë¯¸êµ¬í˜„")

                # ì…ë ¥ ê²€ì¦ í™•ì¸
                total_patterns_checked += 1
                if 'if not' in content or 'is None' in content:
                    patterns_found += 1
                    analysis['error_handling_patterns'].append(f"{file_path.name}: ì…ë ¥ ê²€ì¦ êµ¬í˜„")
                else:
                    analysis['issues'].append(f"{file_path.name}: ì…ë ¥ ê²€ì¦ ë¶€ì¡±")

                # Graceful degradation í™•ì¸
                total_patterns_checked += 1
                if 'return None' in content or 'setVisible(False)' in content:
                    patterns_found += 1
                    analysis['error_handling_patterns'].append(f"{file_path.name}: Graceful degradation êµ¬í˜„")
                else:
                    analysis['issues'].append(f"{file_path.name}: Graceful degradation ë¶€ì¡±")

        # UI í†µí•© íŒŒì¼ì˜ ì•ˆì „ ì„í¬íŠ¸ í™•ì¸
        ui_files = [
            ui_components_path / "file_list_widget.py",
            ui_components_path / "progress_widget.py"
        ]

        for file_path in ui_files:
            if file_path.exists():
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                # ì˜µì…”ë„ ì„í¬íŠ¸ íŒ¨í„´ í™•ì¸
                total_patterns_checked += 1
                if 'try:' in content and 'ImportError:' in content:
                    patterns_found += 1
                    analysis['error_handling_patterns'].append(f"{file_path.name}: ì•ˆì „í•œ OCR ì„í¬íŠ¸ íŒ¨í„´")
                else:
                    analysis['issues'].append(f"{file_path.name}: ì•ˆì „í•œ ì„í¬íŠ¸ íŒ¨í„´ ë¶€ì¡±")

        # ê²¬ê³ ì„± ì ìˆ˜ ê³„ì‚°
        if total_patterns_checked > 0:
            analysis['robustness_score'] = patterns_found / total_patterns_checked
        else:
            analysis['robustness_score'] = 0

        if analysis['robustness_score'] < 0.7:
            analysis['passed'] = False
            analysis['issues'].append(f"ì „ì²´ ê²¬ê³ ì„± ì ìˆ˜ê°€ ë‚®ìŒ: {analysis['robustness_score']:.1%}")

        return analysis

    def analyze_accessibility_compliance(self) -> Dict[str, Any]:
        """ì ‘ê·¼ì„± ì¤€ìˆ˜ ë¶„ì„"""
        print("6. ì ‘ê·¼ì„± ì¤€ìˆ˜ ë¶„ì„ ì¤‘...")

        analysis = {
            'test_name': 'Accessibility Compliance',
            'passed': True,
            'issues': [],
            'accessibility_features': [],
            'wcag_compliance': {}
        }

        # íˆ´íŒ êµ¬í˜„ í™•ì¸ (WCAG 1.3.1)
        status_provider_path = ocr_ui_path / "ocr_status_provider.py"
        if status_provider_path.exists():
            with open(status_provider_path, 'r', encoding='utf-8') as f:
                content = f.read()

            if 'setToolTip' in content:
                analysis['accessibility_features'].append("Tooltips: ìƒíƒœ ë°°ì§€ íˆ´íŒ êµ¬í˜„")
                analysis['wcag_compliance']['1.3.1_info_relationships'] = True
            else:
                analysis['issues'].append("Accessibility: ìƒíƒœ ë°°ì§€ íˆ´íŒ ë¯¸êµ¬í˜„")
                analysis['wcag_compliance']['1.3.1_info_relationships'] = False

            # í•œê¸€ ì§€ì› í™•ì¸ (êµ­ì œí™”)
            if any(ord(c) >= 0xAC00 and ord(c) <= 0xD7A3 for c in content):
                analysis['accessibility_features'].append("Localization: í•œê¸€ ì¸í„°í˜ì´ìŠ¤ ì§€ì›")
                analysis['wcag_compliance']['3.1.1_language'] = True
            else:
                analysis['issues'].append("Accessibility: í•œê¸€ ì§€ì› ë¯¸í™•ì¸")
                analysis['wcag_compliance']['3.1.1_language'] = False

        # ìƒ‰ìƒ ê¸°ë°˜ì´ ì•„ë‹Œ ì •ë³´ ì „ë‹¬ í™•ì¸ (WCAG 1.4.1)
        if status_provider_path.exists():
            with open(status_provider_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # í…ìŠ¤íŠ¸ ê¸°ë°˜ ì •ë³´ í™•ì¸
            if "'text':" in content and "drawText" in content:
                analysis['accessibility_features'].append("Color Independence: ìƒ‰ìƒê³¼ í•¨ê»˜ í…ìŠ¤íŠ¸ ì •ë³´ ì œê³µ")
                analysis['wcag_compliance']['1.4.1_color_usage'] = True
            else:
                analysis['issues'].append("Accessibility: ìƒ‰ìƒì—ë§Œ ì˜ì¡´í•œ ì •ë³´ ì „ë‹¬")
                analysis['wcag_compliance']['1.4.1_color_usage'] = False

        # í‚¤ë³´ë“œ ë„¤ë¹„ê²Œì´ì…˜ (WCAG 2.1.1)
        file_list_path = ui_components_path / "file_list_widget.py"
        if file_list_path.exists():
            with open(file_list_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # í¬ì»¤ìŠ¤ ì •ì±… í™•ì¸
            if 'focusPolicy' in content or 'TabFocus' in content:
                analysis['accessibility_features'].append("Keyboard Navigation: í‚¤ë³´ë“œ í¬ì»¤ìŠ¤ ì§€ì›")
                analysis['wcag_compliance']['2.1.1_keyboard'] = True
            else:
                analysis['accessibility_features'].append("Keyboard Navigation: ê¸°ë³¸ Qt í‚¤ë³´ë“œ ì§€ì› (ì¶”ì •)")
                analysis['wcag_compliance']['2.1.1_keyboard'] = True  # Qt ê¸°ë³¸ ì§€ì›

        # ì˜ë¯¸ ìˆëŠ” ì‹œí€€ìŠ¤ í™•ì¸ (WCAG 1.3.2)
        if 'QHBoxLayout' in content or 'QVBoxLayout' in content:
            analysis['accessibility_features'].append("Meaningful Sequence: ë…¼ë¦¬ì  ë ˆì´ì•„ì›ƒ êµ¬ì¡°")
            analysis['wcag_compliance']['1.3.2_meaningful_sequence'] = True
        else:
            analysis['wcag_compliance']['1.3.2_meaningful_sequence'] = False

        # ì „ì²´ WCAG ì¤€ìˆ˜ë„ ê³„ì‚°
        compliance_items = list(analysis['wcag_compliance'].values())
        if compliance_items:
            compliance_rate = sum(compliance_items) / len(compliance_items)
            analysis['wcag_compliance']['overall_rate'] = compliance_rate

            if compliance_rate < 0.8:  # 80% ë¯¸ë§Œ
                analysis['passed'] = False
                analysis['issues'].append(f"WCAG ì¤€ìˆ˜ë„ê°€ ë‚®ìŒ: {compliance_rate:.1%}")

        return analysis

    def generate_comprehensive_report(self) -> str:
        """ì¢…í•© ë³´ê³ ì„œ ìƒì„±"""
        print("\n=== OCR UI Integration QA ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„± ===")

        # ëª¨ë“  ë¶„ì„ ì‹¤í–‰
        analyses = [
            self.analyze_code_structure(),
            self.analyze_feature_integration(),
            self.analyze_ui_patterns(),
            self.analyze_performance_considerations(),
            self.analyze_error_handling(),
            self.analyze_accessibility_compliance()
        ]

        # ì „ì²´ ê²°ê³¼ ì§‘ê³„
        total_tests = len(analyses)
        passed_tests = sum(1 for a in analyses if a['passed'])
        total_issues = sum(len(a['issues']) for a in analyses)

        # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        quality_score = (passed_tests / total_tests) * 100 if total_tests > 0 else 0

        # ìš°ì„ ìˆœìœ„ë³„ ì´ìŠˆ ë¶„ë¥˜
        high_priority = []
        medium_priority = []
        low_priority = []

        for analysis in analyses:
            for issue in analysis['issues']:
                if any(keyword in issue.lower() for keyword in ['ì—†ìŒ', 'ë¯¸êµ¬í˜„', 'ì‹¤íŒ¨', 'ì˜ˆì™¸']):
                    high_priority.append(f"{analysis['test_name']}: {issue}")
                elif any(keyword in issue.lower() for keyword in ['ì„±ëŠ¥', 'ëŠë¦¼', 'í¬ê¸°', 'ë©”ëª¨ë¦¬']):
                    medium_priority.append(f"{analysis['test_name']}: {issue}")
                else:
                    low_priority.append(f"{analysis['test_name']}: {issue}")

        # ë³´ê³ ì„œ ìƒì„±
        end_time = datetime.now()
        analysis_time = (end_time - self.start_time).total_seconds()

        overall_status = "âœ… PASS" if quality_score >= 80 and total_issues == 0 else "âŒ NEEDS IMPROVEMENT"
        if quality_score >= 80 and total_issues <= 5:
            overall_status = "âš ï¸ CONDITIONAL PASS"

        report = f"""
# OCR UI Integration - QA ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ

## ì „ì²´ í‰ê°€: {overall_status}

**ë¶„ì„ ì™„ë£Œ ì‹œê°„**: {end_time.strftime('%Y-%m-%d %H:%M:%S')}
**ë¶„ì„ ì†Œìš” ì‹œê°„**: {analysis_time:.2f}ì´ˆ
**í’ˆì§ˆ ì ìˆ˜**: {quality_score:.1f}/100
**ì „ì²´ í…ŒìŠ¤íŠ¸**: {total_tests}ê°œ
**í†µê³¼ í…ŒìŠ¤íŠ¸**: {passed_tests}ê°œ
**ì‹¤íŒ¨ í…ŒìŠ¤íŠ¸**: {total_tests - passed_tests}ê°œ
**ë°œê²¬ëœ ì´ìŠˆ**: {total_issues}ê°œ

## ìƒì„¸ ë¶„ì„ ê²°ê³¼

"""

        # ê° ë¶„ì„ ê²°ê³¼ ì¶”ê°€
        for analysis in analyses:
            status = "âœ… PASS" if analysis['passed'] else "âŒ FAIL"
            report += f"### {status} {analysis['test_name']}\n\n"

            if analysis['issues']:
                report += "**ë°œê²¬ëœ ì´ìŠˆ:**\n"
                for issue in analysis['issues']:
                    report += f"- {issue}\n"
                report += "\n"

            # ê¸ì •ì ì¸ ë°œê²¬ì‚¬í•­
            positive_keys = ['patterns_found', 'optimizations_found', 'error_handling_patterns',
                           'accessibility_features', 'integration_points']

            for key in positive_keys:
                if key in analysis and analysis[key]:
                    report += f"**{key.replace('_', ' ').title()}:**\n"
                    for item in analysis[key]:
                        report += f"- {item}\n"
                    report += "\n"

        # ìš°ì„ ìˆœìœ„ë³„ ì´ìŠˆ ìš”ì•½
        report += "## ì´ìŠˆ ìš°ì„ ìˆœìœ„\n\n"

        if high_priority:
            report += "### ğŸ”¥ ë†’ì€ ìš°ì„ ìˆœìœ„ (ì¦‰ì‹œ ìˆ˜ì • í•„ìš”)\n"
            for issue in high_priority:
                report += f"- {issue}\n"
            report += "\n"

        if medium_priority:
            report += "### âš¡ ì¤‘ê°„ ìš°ì„ ìˆœìœ„ (ì„±ëŠ¥/í’ˆì§ˆ ê°œì„ )\n"
            for issue in medium_priority:
                report += f"- {issue}\n"
            report += "\n"

        if low_priority:
            report += "### ğŸ“ ë‚®ì€ ìš°ì„ ìˆœìœ„ (ê°œì„  ê¶Œì¥)\n"
            for issue in low_priority:
                report += f"- {issue}\n"
            report += "\n"

        # ê¶Œì¥ì‚¬í•­
        report += "## ê¶Œì¥ì‚¬í•­\n\n"

        if quality_score >= 90 and total_issues == 0:
            report += "ğŸ‰ **ìš°ìˆ˜í•œ êµ¬í˜„í’ˆì§ˆ!**\n\n"
            report += "- í”„ë¡œë•ì…˜ ë°°í¬ ì¤€ë¹„ ì™„ë£Œ\n"
            report += "- ì½”ë“œ í’ˆì§ˆê³¼ ì•„í‚¤í…ì²˜ê°€ ìš°ìˆ˜í•¨\n"
            report += "- ì„±ëŠ¥ ìµœì í™”ì™€ ì—ëŸ¬ ì²˜ë¦¬ê°€ ì˜ êµ¬í˜„ë¨\n"
            report += "- ì ‘ê·¼ì„± ê³ ë ¤ì‚¬í•­ì´ ë°˜ì˜ë¨\n\n"
        elif quality_score >= 80:
            report += "âœ… **ì–‘í˜¸í•œ êµ¬í˜„í’ˆì§ˆ**\n\n"
            report += "- ì†Œìˆ˜ì˜ ê°œì„ ì‚¬í•­ ë°˜ì˜ í›„ ë°°í¬ ê°€ëŠ¥\n"
            report += "- ì „ë°˜ì ì¸ ì•„í‚¤í…ì²˜ëŠ” ê±´ì‹¤í•¨\n"
            report += "- ìš´ì˜ ì „ ì¶”ê°€ í…ŒìŠ¤íŠ¸ ê¶Œì¥\n\n"
        else:
            report += "âš ï¸ **ê°œì„  í•„ìš”**\n\n"
            report += "- ì£¼ìš” ì´ìŠˆë“¤ì„ ìˆ˜ì • í›„ ì¬ê²€í†  í•„ìš”\n"
            report += "- ì•„í‚¤í…ì²˜ ë° ì—ëŸ¬ ì²˜ë¦¬ ë³´ì™„\n"
            report += "- ì„±ëŠ¥ ìµœì í™” ê³ ë ¤\n\n"

        # ê¸°ìˆ ì  ê¶Œì¥ì‚¬í•­
        report += "### ê¸°ìˆ ì  ê¶Œì¥ì‚¬í•­\n\n"

        if any('ìºì‹±' in str(analyses) for analysis in analyses):
            report += "1. **ìºì‹± ì „ëµ**: QCache í™œìš©ì´ ì˜ êµ¬í˜„ë˜ì–´ ìˆìŒ\n"
        else:
            report += "1. **ìºì‹± êµ¬í˜„**: ì„±ëŠ¥ ê°œì„ ì„ ìœ„í•œ ìºì‹± ì „ëµ í•„ìš”\n"

        if any('ì—ëŸ¬' in str(analyses) for analysis in analyses):
            report += "2. **ì—ëŸ¬ ì²˜ë¦¬**: ê²¬ê³ í•œ ì˜ˆì™¸ ì²˜ë¦¬ êµ¬í˜„ í•„ìš”\n"
        else:
            report += "2. **ì—ëŸ¬ ì²˜ë¦¬**: ì˜ˆì™¸ ì²˜ë¦¬ê°€ ì ì ˆíˆ êµ¬í˜„ë¨\n"

        report += "3. **í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€**: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ë° í†µí•© í…ŒìŠ¤íŠ¸ ì¶”ê°€ ê¶Œì¥\n"
        report += "4. **ë¬¸ì„œí™”**: API ë¬¸ì„œ ë° ì‚¬ìš©ì ê°€ì´ë“œ ë³´ì™„\n"
        report += "5. **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**: í”„ë¡œë•ì…˜ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì„¤ì •\n\n"

        # ë‹¤ìŒ ë‹¨ê³„
        report += "## ë‹¤ìŒ ë‹¨ê³„\n\n"

        if quality_score >= 85:
            report += "1. âœ… í”„ë¡œë•ì…˜ ë°°í¬ ì§„í–‰\n"
            report += "2. ğŸ” ì‚¬ìš©ì ìŠ¹ì¸ í…ŒìŠ¤íŠ¸ (UAT) ì‹¤ì‹œ\n"
            report += "3. ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì„¤ì •\n"
            report += "4. ğŸ‘¥ ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘\n"
        else:
            report += "1. ğŸ”§ ë°œê²¬ëœ ì´ìŠˆ ìˆ˜ì •\n"
            report += "2. ğŸ§ª ìˆ˜ì •ì‚¬í•­ ì¬í…ŒìŠ¤íŠ¸\n"
            report += "3. ğŸ“‹ ì½”ë“œ ë¦¬ë·° ì‹¤ì‹œ\n"
            report += "4. âœ… í’ˆì§ˆ ê²Œì´íŠ¸ ì¬í‰ê°€\n"

        report += f"""
## ë©”íŠ¸ë¦­ ìš”ì•½

| í•­ëª© | ê°’ |
|------|-----|
| ì „ì²´ í’ˆì§ˆ ì ìˆ˜ | {quality_score:.1f}/100 |
| í…ŒìŠ¤íŠ¸ í†µê³¼ìœ¨ | {(passed_tests/total_tests)*100:.1f}% |
| ë°œê²¬ëœ ì´ìŠˆ | {total_issues}ê°œ |
| ë¶„ì„ íŒŒì¼ ìˆ˜ | 5ê°œ |
| ì½”ë“œ ë¼ì¸ ìˆ˜ | ~2,000ì¤„ (ì¶”ì •) |

## ê²°ë¡ 

OCR UI Integration ê¸°ëŠ¥ì€ {"ë†’ì€" if quality_score >= 80 else "ë³´í†µ" if quality_score >= 60 else "ë‚®ì€"} í’ˆì§ˆë¡œ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤.
{"í”„ë¡œë•ì…˜ ë°°í¬ê°€ ê°€ëŠ¥í•œ ìƒíƒœ" if quality_score >= 80 else "ì¶”ê°€ ê°œì„ ì´ í•„ìš”í•œ ìƒíƒœ"}ì´ë©°,
ì‚¬ìš©ì ê²½í—˜ê³¼ ì‹œìŠ¤í…œ ì•ˆì •ì„±ì„ ìœ„í•œ {"ìµœì†Œí•œì˜" if quality_score >= 80 else "ìƒë‹¹í•œ"} ë³´ì™„ì´ í•„ìš”í•©ë‹ˆë‹¤.

---
*QA Analysis Tool v1.0*
*Generated: {end_time.isoformat()}*
"""

        return report


def main():
    """ë©”ì¸ ë¶„ì„ ì‹¤í–‰"""
    analyzer = OCRUIIntegrationQAAnalyzer()

    try:
        print("OCR UI Integration - ì •ì  ë¶„ì„ ë° í’ˆì§ˆ í‰ê°€ ì‹œì‘")
        print("=" * 60)

        # ì¢…í•© ë³´ê³ ì„œ ìƒì„±
        report = analyzer.generate_comprehensive_report()

        # ê²°ê³¼ ì¶œë ¥
        print(report)

        # ë³´ê³ ì„œ íŒŒì¼ ì €ì¥
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_path = project_root / f"ocr_ui_integration_qa_report_{timestamp}.md"

        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)

        print(f"\nğŸ“„ ìƒì„¸ ë³´ê³ ì„œ ì €ì¥ë¨: {report_path}")

        # í’ˆì§ˆ ì ìˆ˜ì— ë”°ë¥¸ ì¢…ë£Œ ì½”ë“œ
        overall_quality = sum(1 for a in [
            analyzer.analyze_code_structure(),
            analyzer.analyze_feature_integration(),
            analyzer.analyze_ui_patterns(),
            analyzer.analyze_performance_considerations(),
            analyzer.analyze_error_handling(),
            analyzer.analyze_accessibility_compliance()
        ] if a['passed']) / 6 * 100

        return 0 if overall_quality >= 80 else 1

    except Exception as e:
        print(f"\nâŒ ë¶„ì„ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)